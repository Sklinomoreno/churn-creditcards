# Predicci√≥n de Churn en Tarjetas de Cr√©dito

Este proyecto tiene como objetivo predecir la deserci√≥n de clientes (**churn**) en tarjetas de cr√©dito, utilizando el conjunto de datos **‚ÄúCredit Card Customers‚Äù** disponible en **Kaggle**. El dataset incluye informaci√≥n de 10,127 clientes de un banco, con variables demogr√°ficas, socioecon√≥micas y de comportamiento financiero. Esto lo convierte en una excelente base para analizar el churn y mejorar las estrategias de retenci√≥n.

## üìä Dataset

El conjunto de datos contiene las siguientes variables:

| **Variable**                       | **Descripci√≥n**                                                                |
|-------------------------------------|--------------------------------------------------------------------------------|
| `CLIENTNUM`                         | Identificador √∫nico del cliente                                               |
| `Attrition_Flag`                    | Evento interno: 1 si la cuenta est√° cerrada, 0 si no                           |
| `Customer_Age`                      | Edad del cliente en a√±os                                                      |
| `Gender`                            | G√©nero: M=Masculino, F=Femenino                                               |
| `Dependent_count`                   | N√∫mero de dependientes                                                        |
| `Education_Level`                   | Nivel educativo del titular de la cuenta                                      |
| `Marital_Status`                    | Estado civil: Casado, Soltero, Divorciado, Desconocido                         |
| `Income_Category`                   | Categor√≠a de ingresos anuales del titular                                     |
| `Card_Category`                     | Tipo de tarjeta: Blue, Silver, Gold, Platinum                                 |
| `Months_on_book`                    | Per√≠odo de relaci√≥n con el banco                                               |
| `Total_Relationship_Count`          | N√∫mero total de productos que tiene el cliente                                |
| `Months_Inactive_12_mon`            | N√∫mero de meses inactivos en los √∫ltimos 12 meses                              |
| `Contacts_Count_12_mon`             | N√∫mero de contactos en los √∫ltimos 12 meses                                   |
| `Credit_Limit`                      | L√≠mite de cr√©dito de la tarjeta                                               |
| `Total_Revolving_Bal`               | Saldo rotativo total en la tarjeta de cr√©dito                                 |
| `Avg_Open_To_Buy`                   | L√≠nea de cr√©dito disponible (promedio de los √∫ltimos 12 meses)                 |
| `Total_Amt_Chng_Q4_Q1`              | Cambio en el monto de transacciones (Q4 sobre Q1)                             |
| `Total_Trans_Amt`                   | Monto total de transacciones (√∫ltimos 12 meses)                               |
| `Total_Trans_Ct`                    | Cantidad total de transacciones (√∫ltimos 12 meses)                            |
| `Total_Ct_Chng_Q4_Q1`               | Cambio en la cantidad de transacciones (Q4 sobre Q1)                           |
| `Avg_Utilization_Ratio`             | Tasa promedio de utilizaci√≥n de la tarjeta                                    |

Puedes acceder al dataset completo a trav√©s del siguiente [enlace a Kaggle](https://www.kaggle.com/datasets/sakshigoyal7/credit-card-customers).

## üßë‚Äçüî¨ Metodolog√≠a

1. **Preparaci√≥n de los datos:** Se utiliz√≥ el conjunto de datos **‚ÄúCredit Card Customers‚Äù** de Kaggle. Se realizaron tareas de limpieza y preprocesamiento, como la codificaci√≥n de variables categ√≥ricas y el tratamiento de valores nulos.

2. **T√©cnicas de Balanceo:** Dado que el dataset presenta un desbalance en las clases (churn vs no churn), se implement√≥ la t√©cnica **SMOTETomek** para balancear las clases antes de entrenar los modelos.

3. **Modelos Evaluados:** Se entrenaron y evaluaron varios modelos de machine learning, incluyendo **Random Forest**, **XGBoost**, **LightGBM**, **CatBoost**, entre otros, para identificar el modelo m√°s efectivo en la predicci√≥n del churn.

4. **Optimizaci√≥n de Hiperpar√°metros:** Para optimizar los hiperpar√°metros de los modelos, se utiliz√≥ **GridSearchCV** con validaci√≥n cruzada.


## üìà Resultados de Modelos

Los siguientes modelos fueron evaluados para predecir la deserci√≥n de clientes, utilizando t√©cnicas de resampling con SMOTETomek para equilibrar las clases y la optimizaci√≥n de umbrales basada en el F1-score:

| **Modelo**                  | **Umbral √ìptimo** | **Precision** | **Recall** | **F1-score** | **AUC** |
|-----------------------------|-------------------|---------------|------------|--------------|---------|
| **Random Forest**           | 0.3               | 0.893         | 0.898      | 0.894        | 0.933   |
| **XGBoost**                 | 0.4               | 0.904         | 0.909      | 0.905        | 0.939   |
| **LightGBM**                | 0.4               | 0.908         | 0.912      | 0.909        | 0.942   |
| **Logistic Regression**     | 0.3               | 0.868         | 0.859      | 0.863        | 0.853   |
| **ElasticNet**              | 0.3               | 0.867         | 0.858      | 0.862        | 0.853   |
| **CatBoost**                | 0.3               | 0.901         | 0.907      | 0.899        | 0.940   |
| **ANN (MLP)**               | 0.3               | 0.879         | 0.879      | 0.879        | 0.914   |
| **Naive Bayes**             | 0.3               | 0.840         | 0.723      | 0.757        | 0.813   |

## An√°lisis de Resultados

- **CatBoost** mostr√≥ el mejor desempe√±o con un AUC de 0.940 y un F1-score de 0.899, lo que lo hace el modelo m√°s adecuado para predecir clientes en riesgo de churn.
- **XGBoost** y **LightGBM** tambi√©n tuvieron buenos resultados, con AUCs cercanos a 0.939 y 0.942, respectivamente, pero no lograron superar a CatBoost en precisi√≥n y recall.
- **Logistic Regression** y **ElasticNet** tuvieron un rendimiento moderado, con AUCs de 0.853, lo que los hizo menos efectivos en el contexto de clases desbalanceadas.
- **Naive Bayes** fue el modelo menos efectivo, con un AUC de 0.813 y un F1-score de 0.757.

## üßë‚Äçüíº Conclusiones

- **CatBoost** es el modelo m√°s adecuado para la predicci√≥n del churn, con un excelente balance entre precisi√≥n y recall, especialmente en la identificaci√≥n de clientes que cancelan el servicio.
- Se recomienda utilizar **CatBoost** en la industria financiera para dise√±ar estrategias de retenci√≥n personalizadas.
- Los modelos como **Naive Bayes** y **Regresi√≥n Log√≠stica** mostraron ser menos efectivos debido a la naturaleza desbalanceada de las clases.

## üîó Link al Dashboard

Puedes ver el dashboard interactivo con los resultados del an√°lisis en el siguiente [enlace a Power BI](https://app.powerbi.com/view?r=eyJrIjoiYzAxMTgxZTgtZThiOS00MGVkLWJiZDItOTliYjcwZmM2NWRlIiwidCI6IjBlMGNiMDYwLTA5YWQtNDlmNS1hMDA1LTY4YjliNDlhYTFmNiIsImMiOjR9).

## üì´ Contacto

üë§ **Smith Eusebio Lino Moreno**  
üìß [smlinomoreno@gmail.com](mailto:smlinomoreno@gmail.com)  
üîó [LinkedIn](https://www.linkedin.com/in/slino-moreno)
